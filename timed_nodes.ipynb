{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 'unspoiled_nodes' and wrote results to 'cleaned_nodes.csv'.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "\n",
    "def clean_unspoiled_data(input_filename, output_filename):\n",
    "    # Read the entire file as a string\n",
    "    with open(input_filename, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    lines = data.split('\\n')\n",
    "\n",
    "    # We’ll store rows of [Time, Item Name, Location, Coordinates].\n",
    "    rows = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        # We're looking for lines in the format:\n",
    "        # |Time || {{item icon|Item Name}} || Slot || [[Location]] || (x..,y..) ...\n",
    "        if not line.startswith('|'):\n",
    "            continue\n",
    "        \n",
    "        # Split on '||'\n",
    "        parts = [p.strip() for p in line.split('||')]\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "\n",
    "        # Extract the fields we care about:\n",
    "        # parts[0] -> time  (remove leading '|')\n",
    "        # parts[1] -> item\n",
    "        # parts[3] -> location\n",
    "        # parts[4] -> coordinate\n",
    "        time = parts[0].lstrip('|').strip()\n",
    "        item = parts[1]\n",
    "        location = parts[3]\n",
    "        coordinate = parts[4]\n",
    "\n",
    "        # Combine entire line to detect questlink if needed\n",
    "        entire_line = ' '.join(parts)\n",
    "\n",
    "        # Skip if 'questlink' is in the line\n",
    "        if re.search(r'questlink', entire_line, re.IGNORECASE):\n",
    "            continue\n",
    "\n",
    "        # Clean up the item name:\n",
    "        # e.g., {{item icon|Broad Beans}} => Broad Beans\n",
    "        item_clean = re.sub(r'\\{\\{.*?\\|([^\\}]+)\\}\\}', r'\\1', item)\n",
    "        # Remove leftover braces, \"Collectable\", \"(Item)\" text, etc.\n",
    "        item_clean = re.sub(r'[{}]|\\(Item\\)|Collectable', '', item_clean).strip()\n",
    "\n",
    "        # Skip if the item name has the word \"cluster\" (case-insensitive)\n",
    "        if re.search(r'cluster', item_clean, re.IGNORECASE):\n",
    "            continue\n",
    "\n",
    "        # Clean up location, e.g. [[Il Mheg]] => Il Mheg\n",
    "        location_clean = re.sub(r'\\[\\[|\\]\\]', '', location).strip()\n",
    "\n",
    "        # Add the row\n",
    "        rows.append([time, item_clean, location_clean, coordinate])\n",
    "\n",
    "    # Write results to a CSV\n",
    "    with open(output_filename, 'w', encoding='utf-8', newline='') as out_csv:\n",
    "        writer = csv.writer(out_csv)\n",
    "        writer.writerow([\"Time\", \"Item Name\", \"Location\", \"Coordinates\"])\n",
    "        writer.writerows(rows)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"unspoiled_nodes\"       # The raw file in the current directory\n",
    "    output_file = \"cleaned_nodes.csv\"    # Your desired output CSV\n",
    "    clean_unspoiled_data(input_file, output_file)\n",
    "    print(f\"Processed '{input_file}' and wrote results to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV written to 'final_nodes_with_ids.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load the JSON file with item IDs.\n",
    "with open(\"item_ids.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    item_json = json.load(f)\n",
    "\n",
    "# Build a mapping: lower-case English item name -> item ID\n",
    "item_mapping = {}\n",
    "for item_id, names in item_json.items():\n",
    "    en_name = names.get(\"en\", \"\").strip().lower()\n",
    "    item_mapping[en_name] = item_id\n",
    "\n",
    "# Read in the cleaned nodes CSV.\n",
    "nodes_df = pd.read_csv(\"cleaned_nodes.csv\")\n",
    "\n",
    "# Function to clean item names for matching:\n",
    "# Remove occurrences of \"(Rare)\" (case-insensitive), then lower-case and strip.\n",
    "def clean_item_name(name):\n",
    "    # Remove the substring (Rare) along with any extra spaces\n",
    "    name_clean = re.sub(r'\\s*\\(rare\\)', '', name, flags=re.IGNORECASE)\n",
    "    return name_clean.strip().lower()\n",
    "\n",
    "nodes_df[\"Item Name Clean\"] = nodes_df[\"Item Name\"].apply(clean_item_name)\n",
    "\n",
    "# Function to look up the item ID using the cleaned item name.\n",
    "def get_item_id(row):\n",
    "    name = row[\"Item Name Clean\"]\n",
    "    if name in item_mapping:\n",
    "        return item_mapping[name]\n",
    "    else:\n",
    "        print(f\"Error: No ID found for item '{row['Item Name']}' (cleaned as '{name}').\")\n",
    "        return None\n",
    "\n",
    "# Apply the lookup function to each row.\n",
    "nodes_df[\"ID\"] = nodes_df.apply(get_item_id, axis=1)\n",
    "\n",
    "# Reorder columns to prepend the ID.\n",
    "final_df = nodes_df[[\"ID\", \"Time\", \"Item Name\", \"Location\", \"Coordinates\"]]\n",
    "\n",
    "# Write the final merged CSV.\n",
    "final_df.to_csv(\"final_nodes_with_ids.csv\", index=False)\n",
    "print(\"Merged CSV written to 'final_nodes_with_ids.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Eorzean time (raw): 07:41\n",
      "\n",
      "Active nodes (with time difference in minutes):\n",
      "       ID   Time                 Item Name                    Location  \\\n",
      "53   5365  07:00              Bamboo Stick             Upper La Noscea   \n",
      "52   7595  07:00              Blood Orange             Upper La Noscea   \n",
      "7   33003  08:00    Rarefied White Oak Log                    Kholusia   \n",
      "8   27822  08:00             Russet Popoto                  Amh Araeng   \n",
      "55  10098  08:00            Mazlaya Greens           Western La Noscea   \n",
      "33  12900  08:00            Chysahl Greens  Coerthas Western Highlands   \n",
      "21  19865  08:00                Lotus Root                      Yanxia   \n",
      "54   7593  08:00           La Noscean Leek           Western La Noscea   \n",
      "56   8024  08:00  Waterfowl Feather (Rare)           Western La Noscea   \n",
      "91  32975  08:00     Rarefied Raw Triphane                 The Fringes   \n",
      "83  32983  08:00         Rarefied Sea Salt                 The Tempest   \n",
      "93  19973  08:00             Raw Rhodonite                   The Peaks   \n",
      "92  32977  08:00      Rarefied Raw Kyanite                 The Fringes   \n",
      "82  32985  08:00         Rarefied Raw Onyx                 The Tempest   \n",
      "\n",
      "   Coordinates  time_diff  \n",
      "53   (x28,y25)        -41  \n",
      "52   (x28,y25)        -41  \n",
      "7    (x28,y33)         19  \n",
      "8    (x19,y16)         19  \n",
      "55   (x34,y28)         19  \n",
      "33     (x8,y9)         19  \n",
      "21    (x28,y7)         19  \n",
      "54   (x34,y28)         19  \n",
      "56   (x34,y28)         19  \n",
      "91   (x30,y13)         19  \n",
      "83    (x25,y4)         19  \n",
      "93   (x26,y12)         19  \n",
      "92   (x30,y13)         19  \n",
      "82    (x25,y4)         19  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import re\n",
    "\n",
    "# -----------------------\n",
    "# 1. Compute current Eorzean time in 24-hour format\n",
    "# -----------------------\n",
    "local_epoch = int(time.time() * 1000)\n",
    "epoch = local_epoch * 20.571428571428573\n",
    "minutes = int((epoch / (1000 * 60)) % 60)\n",
    "hours_24 = int((epoch / (1000 * 60 * 60)) % 24)\n",
    "et_time_str = f\"{hours_24:02d}:{minutes:02d}\"\n",
    "print(\"Current Eorzean time (raw):\", et_time_str)\n",
    "current_time = datetime.strptime(et_time_str, \"%H:%M\")\n",
    "\n",
    "# -----------------------\n",
    "# 2. Load final_nodes_with_ids.csv and duplicate ambiguous AM/PM entries\n",
    "# -----------------------\n",
    "df = pd.read_csv(\"final_nodes_with_ids.csv\")\n",
    "\n",
    "new_rows = []\n",
    "\n",
    "def standard_parse_time(time_str):\n",
    "    # If the string contains \"AM\" or \"PM\" (but not ambiguous \"AM/PM\"), parse using 12-hour clock.\n",
    "    if re.search(r'\\b(AM|PM)\\b', time_str, re.IGNORECASE) and \"AM/PM\" not in time_str.upper():\n",
    "        time_str_fixed = re.sub(r'(\\d)(AM|PM)', r'\\1 \\2', time_str, flags=re.IGNORECASE)\n",
    "        return datetime.strptime(time_str_fixed, \"%I:%M %p\")\n",
    "    else:\n",
    "        # Otherwise, assume it’s already in 24-hour format.\n",
    "        return datetime.strptime(time_str, \"%H:%M\")\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    time_str = row[\"Time\"].strip()\n",
    "    # If the time is ambiguous (contains \"AM/PM\"), duplicate the row.\n",
    "    if \"AM/PM\" in time_str.upper():\n",
    "        base_time_str = re.sub(r'\\s*AM/PM', '', time_str, flags=re.IGNORECASE).strip()\n",
    "        base_time = datetime.strptime(base_time_str, \"%H:%M\")\n",
    "        # Create two interpretations:\n",
    "        # AM version: keep the base time as-is (special handling for 12:00).\n",
    "        # PM version: add 12 hours (unless base time is 12:00).\n",
    "        if base_time.hour == 12:\n",
    "            am_time = base_time.replace(hour=0)\n",
    "            pm_time = base_time\n",
    "        else:\n",
    "            am_time = base_time\n",
    "            pm_time = base_time + timedelta(hours=12)\n",
    "        \n",
    "        row_am = row.copy()\n",
    "        row_am[\"Parsed Time\"] = am_time\n",
    "        row_am[\"Time\"] = am_time.strftime(\"%H:%M\")\n",
    "        new_rows.append(row_am)\n",
    "        \n",
    "        row_pm = row.copy()\n",
    "        row_pm[\"Parsed Time\"] = pm_time\n",
    "        row_pm[\"Time\"] = pm_time.strftime(\"%H:%M\")\n",
    "        new_rows.append(row_pm)\n",
    "    else:\n",
    "        parsed = standard_parse_time(time_str)\n",
    "        row_new = row.copy()\n",
    "        row_new[\"Parsed Time\"] = parsed\n",
    "        row_new[\"Time\"] = parsed.strftime(\"%H:%M\")\n",
    "        new_rows.append(row_new)\n",
    "\n",
    "df_new = pd.DataFrame(new_rows)\n",
    "\n",
    "# -----------------------\n",
    "# 3. Compute the time difference (in minutes) between each node’s spawn time and the current time.\n",
    "#    (The difference is computed on a circular 24-hour scale, ranging from -720 to 720.)\n",
    "def compute_time_diff_minutes(node_time, current_time):\n",
    "    node_minutes = node_time.hour * 60 + node_time.minute\n",
    "    current_minutes = current_time.hour * 60 + current_time.minute\n",
    "    diff = ((node_minutes - current_minutes + 720) % 1440) - 720\n",
    "    return diff\n",
    "\n",
    "df_new[\"time_diff\"] = df_new[\"Parsed Time\"].apply(lambda t: compute_time_diff_minutes(t, current_time))\n",
    "\n",
    "# -----------------------\n",
    "# 4. Filter nodes that are active (spawned up to 50 minutes ago or later).\n",
    "#    (No upper bound is set; we simply require time_diff >= -50.)\n",
    "active_df = df_new[df_new[\"time_diff\"] >= -50]\n",
    "active_sorted = active_df.sort_values(by=\"time_diff\")\n",
    "df_active_top10 = active_sorted.head(14)\n",
    "\n",
    "print(\"\\nActive nodes (with time difference in minutes):\")\n",
    "print(df_active_top10[[\"ID\", \"Time\", \"Item Name\", \"Location\", \"Coordinates\", \"time_diff\"]])\n",
    "\n",
    "# Save the active nodes to a CSV file.\n",
    "df_active_top10.to_csv(\"final_nodes_with_ids_sorted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file with market data saved as 'final_nodes_with_ids_market.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from IPython.display import display\n",
    "\n",
    "# -----------------------\n",
    "# 1. Read the active nodes CSV and filter out any rows with \"Rarefied\" in the Item Name.\n",
    "# -----------------------\n",
    "df_sorted = pd.read_csv(\"final_nodes_with_ids_sorted.csv\")\n",
    "df_filtered = df_sorted[~df_sorted[\"Item Name\"].str.contains(\"Rarefied\", case=False, na=False)]\n",
    "df_top10 = df_filtered.head(14).copy()\n",
    "\n",
    "# Define new column names for the market data we want to add.\n",
    "market_columns = [\n",
    "    \"minListing_world\", \n",
    "    \"minListing_dc\", \n",
    "    \"recentPurchase_world\", \n",
    "    \"recentPurchase_dc\", \n",
    "    \"averageSalePrice_dc\", \n",
    "    \"dailySaleVelocity_dc\"\n",
    "]\n",
    "\n",
    "# Initialize the new columns with None.\n",
    "for col in market_columns:\n",
    "    df_top10[col] = None\n",
    "\n",
    "# -----------------------\n",
    "# 2. Set default world and define a function to fetch market data.\n",
    "# -----------------------\n",
    "world = \"Seraph\"\n",
    "\n",
    "def fetch_market_data(item_id, world):\n",
    "    url = f\"https://universalis.app/api/v2/aggregated/{world}/{item_id}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"results\" in data and len(data[\"results\"]) > 0:\n",
    "                result = data[\"results\"][0]\n",
    "                # Extract the required market values.\n",
    "                minListing_world = result.get(\"nq\", {}).get(\"minListing\", {}).get(\"world\", {}).get(\"price\")\n",
    "                minListing_dc = result.get(\"nq\", {}).get(\"minListing\", {}).get(\"dc\", {}).get(\"price\")\n",
    "                recentPurchase_world = result.get(\"nq\", {}).get(\"recentPurchase\", {}).get(\"world\", {}).get(\"price\")\n",
    "                recentPurchase_dc = result.get(\"nq\", {}).get(\"recentPurchase\", {}).get(\"dc\", {}).get(\"price\")\n",
    "                averageSalePrice_dc = result.get(\"nq\", {}).get(\"averageSalePrice\", {}).get(\"dc\", {}).get(\"price\")\n",
    "                dailySaleVelocity_dc = result.get(\"nq\", {}).get(\"dailySaleVelocity\", {}).get(\"dc\", {}).get(\"quantity\")\n",
    "                return {\n",
    "                    \"minListing_world\": minListing_world,\n",
    "                    \"minListing_dc\": minListing_dc,\n",
    "                    \"recentPurchase_world\": recentPurchase_world,\n",
    "                    \"recentPurchase_dc\": recentPurchase_dc,\n",
    "                    \"averageSalePrice_dc\": averageSalePrice_dc,\n",
    "                    \"dailySaleVelocity_dc\": dailySaleVelocity_dc,\n",
    "                }\n",
    "            else:\n",
    "                print(f\"No results found for item ID {item_id}\")\n",
    "        else:\n",
    "            print(f\"Error fetching data for item ID {item_id}. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception for item ID {item_id}: {e}\")\n",
    "    # Return a dict with None values if something went wrong.\n",
    "    return {col: None for col in market_columns}\n",
    "\n",
    "# -----------------------\n",
    "# 3. Loop through the filtered top 10 rows, fetch market data for each item, and update the DataFrame.\n",
    "# -----------------------\n",
    "for idx, row in df_top10.iterrows():\n",
    "    item_id = row[\"ID\"]\n",
    "    market_data = fetch_market_data(item_id, world)\n",
    "    for key, value in market_data.items():\n",
    "        df_top10.at[idx, key] = value\n",
    "\n",
    "# -----------------------\n",
    "# 4. Save the augmented DataFrame to a new CSV file and display it.\n",
    "# -----------------------\n",
    "df_top10.to_csv(\"final_nodes_with_ids_market.csv\", index=False)\n",
    "print(\"CSV file with market data saved as 'final_nodes_with_ids_market.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Item Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Parsed Time</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>minListing_world</th>\n",
       "      <th>minListing_dc</th>\n",
       "      <th>recentPurchase_world</th>\n",
       "      <th>recentPurchase_dc</th>\n",
       "      <th>averageSalePrice_dc</th>\n",
       "      <th>dailySaleVelocity_dc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5365</td>\n",
       "      <td>07:00</td>\n",
       "      <td>Bamboo Stick</td>\n",
       "      <td>Upper La Noscea</td>\n",
       "      <td>(x28,y25)</td>\n",
       "      <td>1900-01-01 07:00:00</td>\n",
       "      <td>-41</td>\n",
       "      <td>338</td>\n",
       "      <td>338</td>\n",
       "      <td>433</td>\n",
       "      <td>433</td>\n",
       "      <td>984.248848</td>\n",
       "      <td>55.975318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7595</td>\n",
       "      <td>07:00</td>\n",
       "      <td>Blood Orange</td>\n",
       "      <td>Upper La Noscea</td>\n",
       "      <td>(x28,y25)</td>\n",
       "      <td>1900-01-01 07:00:00</td>\n",
       "      <td>-41</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27822</td>\n",
       "      <td>08:00</td>\n",
       "      <td>Russet Popoto</td>\n",
       "      <td>Amh Araeng</td>\n",
       "      <td>(x19,y16)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>28048.625000</td>\n",
       "      <td>18.572431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10098</td>\n",
       "      <td>08:00</td>\n",
       "      <td>Mazlaya Greens</td>\n",
       "      <td>Western La Noscea</td>\n",
       "      <td>(x34,y28)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>395</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12900</td>\n",
       "      <td>08:00</td>\n",
       "      <td>Chysahl Greens</td>\n",
       "      <td>Coerthas Western Highlands</td>\n",
       "      <td>(x8,y9)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>800</td>\n",
       "      <td>60</td>\n",
       "      <td>182.293023</td>\n",
       "      <td>55.459274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19865</td>\n",
       "      <td>08:00</td>\n",
       "      <td>Lotus Root</td>\n",
       "      <td>Yanxia</td>\n",
       "      <td>(x28,y7)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>15.954545</td>\n",
       "      <td>11.349788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7593</td>\n",
       "      <td>08:00</td>\n",
       "      <td>La Noscean Leek</td>\n",
       "      <td>Western La Noscea</td>\n",
       "      <td>(x34,y28)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>99</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8024</td>\n",
       "      <td>08:00</td>\n",
       "      <td>Waterfowl Feather (Rare)</td>\n",
       "      <td>Western La Noscea</td>\n",
       "      <td>(x34,y28)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>776</td>\n",
       "      <td>200</td>\n",
       "      <td>390</td>\n",
       "      <td>398</td>\n",
       "      <td>450.386813</td>\n",
       "      <td>117.366974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19973</td>\n",
       "      <td>08:00</td>\n",
       "      <td>Raw Rhodonite</td>\n",
       "      <td>The Peaks</td>\n",
       "      <td>(x26,y12)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>2000</td>\n",
       "      <td>799</td>\n",
       "      <td>2498</td>\n",
       "      <td>2498</td>\n",
       "      <td>1083.860987</td>\n",
       "      <td>115.045354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID   Time                 Item Name                    Location  \\\n",
       "0   5365  07:00              Bamboo Stick             Upper La Noscea   \n",
       "1   7595  07:00              Blood Orange             Upper La Noscea   \n",
       "2  27822  08:00             Russet Popoto                  Amh Araeng   \n",
       "3  10098  08:00            Mazlaya Greens           Western La Noscea   \n",
       "4  12900  08:00            Chysahl Greens  Coerthas Western Highlands   \n",
       "5  19865  08:00                Lotus Root                      Yanxia   \n",
       "6   7593  08:00           La Noscean Leek           Western La Noscea   \n",
       "7   8024  08:00  Waterfowl Feather (Rare)           Western La Noscea   \n",
       "8  19973  08:00             Raw Rhodonite                   The Peaks   \n",
       "\n",
       "  Coordinates          Parsed Time  time_diff  minListing_world  \\\n",
       "0   (x28,y25)  1900-01-01 07:00:00        -41               338   \n",
       "1   (x28,y25)  1900-01-01 07:00:00        -41                63   \n",
       "2   (x19,y16)  1900-01-01 08:00:00         19                 8   \n",
       "3   (x34,y28)  1900-01-01 08:00:00         19               395   \n",
       "4     (x8,y9)  1900-01-01 08:00:00         19               100   \n",
       "5    (x28,y7)  1900-01-01 08:00:00         19                10   \n",
       "6   (x34,y28)  1900-01-01 08:00:00         19                99   \n",
       "7   (x34,y28)  1900-01-01 08:00:00         19               776   \n",
       "8   (x26,y12)  1900-01-01 08:00:00         19              2000   \n",
       "\n",
       "   minListing_dc  recentPurchase_world  recentPurchase_dc  \\\n",
       "0            338                   433                433   \n",
       "1              1                     1                  1   \n",
       "2              7                     9                100   \n",
       "3             20                   100                200   \n",
       "4             15                   800                 60   \n",
       "5              5                    10                300   \n",
       "6              8                    90                 30   \n",
       "7            200                   390                398   \n",
       "8            799                  2498               2498   \n",
       "\n",
       "   averageSalePrice_dc  dailySaleVelocity_dc  \n",
       "0           984.248848             55.975318  \n",
       "1                  NaN                   NaN  \n",
       "2         28048.625000             18.572431  \n",
       "3                  NaN                   NaN  \n",
       "4           182.293023             55.459274  \n",
       "5            15.954545             11.349788  \n",
       "6                  NaN                   NaN  \n",
       "7           450.386813            117.366974  \n",
       "8          1083.860987            115.045354  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the final CSV with market data (20 rows)\n",
    "df_market = pd.read_csv(\"final_nodes_with_ids_market.csv\")\n",
    "\n",
    "from IPython.display import display\n",
    "display(df_market)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file with market data saved as 'final_nodes_with_ids_market.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# -----------------------\n",
    "# 1. Read the previously generated sorted CSV and take the first 10 rows that do NOT contain \"Rarefied\" in the Item Name.\n",
    "# -----------------------\n",
    "df_sorted = pd.read_csv(\"final_nodes_with_ids_sorted.csv\")\n",
    "\n",
    "# Filter out rows that have \"Rarefied\" in the Item Name (case-insensitive)\n",
    "df_filtered = df_sorted[~df_sorted[\"Item Name\"].str.contains(\"Rarefied\", case=False, na=False)]\n",
    "df_top10 = df_filtered.head(14).copy()\n",
    "\n",
    "# Define new column names for the market data we want to add.\n",
    "market_columns = [\n",
    "    \"minListing_world\", \n",
    "    \"minListing_dc\", \n",
    "    \"recentPurchase_world\", \n",
    "    \"recentPurchase_dc\", \n",
    "    \"averageSalePrice_dc\", \n",
    "    \"dailySaleVelocity_dc\"\n",
    "]\n",
    "\n",
    "# Initialize the new columns with None.\n",
    "for col in market_columns:\n",
    "    df_top10[col] = None\n",
    "\n",
    "# -----------------------\n",
    "# 2. Set default world and define a function to fetch market data.\n",
    "# -----------------------\n",
    "world = \"Seraph\"\n",
    "\n",
    "def fetch_market_data(item_id, world):\n",
    "    url = f\"https://universalis.app/api/v2/aggregated/{world}/{item_id}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"results\" in data and len(data[\"results\"]) > 0:\n",
    "                result = data[\"results\"][0]\n",
    "                # Extract the required market values.\n",
    "                minListing_world = result.get(\"nq\", {}).get(\"minListing\", {}).get(\"world\", {}).get(\"price\")\n",
    "                minListing_dc = result.get(\"nq\", {}).get(\"minListing\", {}).get(\"dc\", {}).get(\"price\")\n",
    "                recentPurchase_world = result.get(\"nq\", {}).get(\"recentPurchase\", {}).get(\"world\", {}).get(\"price\")\n",
    "                recentPurchase_dc = result.get(\"nq\", {}).get(\"recentPurchase\", {}).get(\"dc\", {}).get(\"price\")\n",
    "                averageSalePrice_dc = result.get(\"nq\", {}).get(\"averageSalePrice\", {}).get(\"dc\", {}).get(\"price\")\n",
    "                dailySaleVelocity_dc = result.get(\"nq\", {}).get(\"dailySaleVelocity\", {}).get(\"dc\", {}).get(\"quantity\")\n",
    "                return {\n",
    "                    \"minListing_world\": minListing_world,\n",
    "                    \"minListing_dc\": minListing_dc,\n",
    "                    \"recentPurchase_world\": recentPurchase_world,\n",
    "                    \"recentPurchase_dc\": recentPurchase_dc,\n",
    "                    \"averageSalePrice_dc\": averageSalePrice_dc,\n",
    "                    \"dailySaleVelocity_dc\": dailySaleVelocity_dc,\n",
    "                }\n",
    "            else:\n",
    "                print(f\"No results found for item ID {item_id}\")\n",
    "        else:\n",
    "            print(f\"Error fetching data for item ID {item_id}. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception for item ID {item_id}: {e}\")\n",
    "    # Return a dict with None values if something went wrong.\n",
    "    return {col: None for col in market_columns}\n",
    "\n",
    "# -----------------------\n",
    "# 3. Loop through the first 10 rows, fetch market data for each item, and update the DataFrame.\n",
    "# -----------------------\n",
    "for idx, row in df_top10.iterrows():\n",
    "    # Assuming the column \"ID\" in the CSV corresponds to the ItemID.\n",
    "    item_id = row[\"ID\"]\n",
    "    market_data = fetch_market_data(item_id, world)\n",
    "    for key, value in market_data.items():\n",
    "        df_top10.at[idx, key] = value\n",
    "\n",
    "# -----------------------\n",
    "# 4. Save the augmented DataFrame to a new CSV file.\n",
    "# -----------------------\n",
    "df_top10.to_csv(\"final_nodes_with_ids_market.csv\", index=False)\n",
    "print(\"CSV file with market data saved as 'final_nodes_with_ids_market.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Item Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Parsed Time</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>minListing_world</th>\n",
       "      <th>minListing_dc</th>\n",
       "      <th>recentPurchase_world</th>\n",
       "      <th>recentPurchase_dc</th>\n",
       "      <th>averageSalePrice_dc</th>\n",
       "      <th>dailySaleVelocity_dc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5365</td>\n",
       "      <td>07:00</td>\n",
       "      <td>Bamboo Stick</td>\n",
       "      <td>Upper La Noscea</td>\n",
       "      <td>(x28,y25)</td>\n",
       "      <td>1900-01-01 07:00:00</td>\n",
       "      <td>-41</td>\n",
       "      <td>338</td>\n",
       "      <td>338</td>\n",
       "      <td>433</td>\n",
       "      <td>433</td>\n",
       "      <td>984.248848</td>\n",
       "      <td>55.974936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7595</td>\n",
       "      <td>07:00</td>\n",
       "      <td>Blood Orange</td>\n",
       "      <td>Upper La Noscea</td>\n",
       "      <td>(x28,y25)</td>\n",
       "      <td>1900-01-01 07:00:00</td>\n",
       "      <td>-41</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27822</td>\n",
       "      <td>08:00</td>\n",
       "      <td>Russet Popoto</td>\n",
       "      <td>Amh Araeng</td>\n",
       "      <td>(x19,y16)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>28048.625000</td>\n",
       "      <td>18.572293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10098</td>\n",
       "      <td>08:00</td>\n",
       "      <td>Mazlaya Greens</td>\n",
       "      <td>Western La Noscea</td>\n",
       "      <td>(x34,y28)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>395</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12900</td>\n",
       "      <td>08:00</td>\n",
       "      <td>Chysahl Greens</td>\n",
       "      <td>Coerthas Western Highlands</td>\n",
       "      <td>(x8,y9)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>800</td>\n",
       "      <td>60</td>\n",
       "      <td>182.293023</td>\n",
       "      <td>55.458859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19865</td>\n",
       "      <td>08:00</td>\n",
       "      <td>Lotus Root</td>\n",
       "      <td>Yanxia</td>\n",
       "      <td>(x28,y7)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>15.954545</td>\n",
       "      <td>11.349711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7593</td>\n",
       "      <td>08:00</td>\n",
       "      <td>La Noscean Leek</td>\n",
       "      <td>Western La Noscea</td>\n",
       "      <td>(x34,y28)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>99</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8024</td>\n",
       "      <td>08:00</td>\n",
       "      <td>Waterfowl Feather (Rare)</td>\n",
       "      <td>Western La Noscea</td>\n",
       "      <td>(x34,y28)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>776</td>\n",
       "      <td>200</td>\n",
       "      <td>390</td>\n",
       "      <td>398</td>\n",
       "      <td>450.386813</td>\n",
       "      <td>117.366160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19973</td>\n",
       "      <td>08:00</td>\n",
       "      <td>Raw Rhodonite</td>\n",
       "      <td>The Peaks</td>\n",
       "      <td>(x26,y12)</td>\n",
       "      <td>1900-01-01 08:00:00</td>\n",
       "      <td>19</td>\n",
       "      <td>2000</td>\n",
       "      <td>799</td>\n",
       "      <td>2498</td>\n",
       "      <td>2498</td>\n",
       "      <td>1083.860987</td>\n",
       "      <td>115.044438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID   Time                 Item Name                    Location  \\\n",
       "0   5365  07:00              Bamboo Stick             Upper La Noscea   \n",
       "1   7595  07:00              Blood Orange             Upper La Noscea   \n",
       "2  27822  08:00             Russet Popoto                  Amh Araeng   \n",
       "3  10098  08:00            Mazlaya Greens           Western La Noscea   \n",
       "4  12900  08:00            Chysahl Greens  Coerthas Western Highlands   \n",
       "5  19865  08:00                Lotus Root                      Yanxia   \n",
       "6   7593  08:00           La Noscean Leek           Western La Noscea   \n",
       "7   8024  08:00  Waterfowl Feather (Rare)           Western La Noscea   \n",
       "8  19973  08:00             Raw Rhodonite                   The Peaks   \n",
       "\n",
       "  Coordinates          Parsed Time  time_diff  minListing_world  \\\n",
       "0   (x28,y25)  1900-01-01 07:00:00        -41               338   \n",
       "1   (x28,y25)  1900-01-01 07:00:00        -41                63   \n",
       "2   (x19,y16)  1900-01-01 08:00:00         19                 8   \n",
       "3   (x34,y28)  1900-01-01 08:00:00         19               395   \n",
       "4     (x8,y9)  1900-01-01 08:00:00         19               100   \n",
       "5    (x28,y7)  1900-01-01 08:00:00         19                10   \n",
       "6   (x34,y28)  1900-01-01 08:00:00         19                99   \n",
       "7   (x34,y28)  1900-01-01 08:00:00         19               776   \n",
       "8   (x26,y12)  1900-01-01 08:00:00         19              2000   \n",
       "\n",
       "   minListing_dc  recentPurchase_world  recentPurchase_dc  \\\n",
       "0            338                   433                433   \n",
       "1              1                     1                  1   \n",
       "2              7                     9                100   \n",
       "3             20                   100                200   \n",
       "4             15                   800                 60   \n",
       "5              5                    10                300   \n",
       "6              8                    90                 30   \n",
       "7            200                   390                398   \n",
       "8            799                  2498               2498   \n",
       "\n",
       "   averageSalePrice_dc  dailySaleVelocity_dc  \n",
       "0           984.248848             55.974936  \n",
       "1                  NaN                   NaN  \n",
       "2         28048.625000             18.572293  \n",
       "3                  NaN                   NaN  \n",
       "4           182.293023             55.458859  \n",
       "5            15.954545             11.349711  \n",
       "6                  NaN                   NaN  \n",
       "7           450.386813            117.366160  \n",
       "8          1083.860987            115.044438  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Read the final CSV with market data.\n",
    "df_market = pd.read_csv(\"final_nodes_with_ids_market.csv\")\n",
    "\n",
    "# Ensure we only display rows that do NOT have \"Rarefied\" in the Item Name.\n",
    "df_market_filtered = df_market[~df_market[\"Item Name\"].str.contains(\"Rarefied\", case=False, na=False)]\n",
    "\n",
    "# Display the filtered DataFrame.\n",
    "display(df_market_filtered)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
