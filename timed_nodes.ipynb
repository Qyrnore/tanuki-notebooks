{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 'unspoiled_nodes' and wrote results to 'cleaned_nodes.csv'.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "\n",
    "def clean_unspoiled_data(input_filename, output_filename):\n",
    "    # Read the entire file as a string\n",
    "    with open(input_filename, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    lines = data.split('\\n')\n",
    "\n",
    "    # Weâ€™ll store rows of [Time, Item Name, Location, Coordinates].\n",
    "    rows = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        # We're looking for lines in the format:\n",
    "        # |Time || {{item icon|Item Name}} || Slot || [[Location]] || (x..,y..) ...\n",
    "        if not line.startswith('|'):\n",
    "            continue\n",
    "        \n",
    "        # Split on '||'\n",
    "        parts = [p.strip() for p in line.split('||')]\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "\n",
    "        # Extract the fields we care about:\n",
    "        # parts[0] -> time  (remove leading '|')\n",
    "        # parts[1] -> item\n",
    "        # parts[3] -> location\n",
    "        # parts[4] -> coordinate\n",
    "        time = parts[0].lstrip('|').strip()\n",
    "        item = parts[1]\n",
    "        location = parts[3]\n",
    "        coordinate = parts[4]\n",
    "\n",
    "        # Combine entire line to detect questlink if needed\n",
    "        entire_line = ' '.join(parts)\n",
    "\n",
    "        # Skip if 'questlink' is in the line\n",
    "        if re.search(r'questlink', entire_line, re.IGNORECASE):\n",
    "            continue\n",
    "\n",
    "        # Clean up the item name:\n",
    "        # e.g., {{item icon|Broad Beans}} => Broad Beans\n",
    "        item_clean = re.sub(r'\\{\\{.*?\\|([^\\}]+)\\}\\}', r'\\1', item)\n",
    "        # Remove leftover braces, \"Collectable\", \"(Item)\" text, etc.\n",
    "        item_clean = re.sub(r'[{}]|\\(Item\\)|Collectable', '', item_clean).strip()\n",
    "\n",
    "        # Skip if the item name has the word \"cluster\" (case-insensitive)\n",
    "        if re.search(r'cluster', item_clean, re.IGNORECASE):\n",
    "            continue\n",
    "\n",
    "        # Clean up location, e.g. [[Il Mheg]] => Il Mheg\n",
    "        location_clean = re.sub(r'\\[\\[|\\]\\]', '', location).strip()\n",
    "\n",
    "        # Add the row\n",
    "        rows.append([time, item_clean, location_clean, coordinate])\n",
    "\n",
    "    # Write results to a CSV\n",
    "    with open(output_filename, 'w', encoding='utf-8', newline='') as out_csv:\n",
    "        writer = csv.writer(out_csv)\n",
    "        writer.writerow([\"Time\", \"Item Name\", \"Location\", \"Coordinates\"])\n",
    "        writer.writerows(rows)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"unspoiled_nodes\"       # The raw file in the current directory\n",
    "    output_file = \"cleaned_nodes.csv\"    # Your desired output CSV\n",
    "    clean_unspoiled_data(input_file, output_file)\n",
    "    print(f\"Processed '{input_file}' and wrote results to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV written to 'final_nodes_with_ids.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Load the JSON file with item IDs.\n",
    "with open(\"item_ids.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    item_json = json.load(f)\n",
    "\n",
    "# Build a mapping: lower-case English item name -> item ID\n",
    "item_mapping = {}\n",
    "for item_id, names in item_json.items():\n",
    "    en_name = names.get(\"en\", \"\").strip().lower()\n",
    "    item_mapping[en_name] = item_id\n",
    "\n",
    "# Read in the cleaned nodes CSV.\n",
    "nodes_df = pd.read_csv(\"cleaned_nodes.csv\")\n",
    "\n",
    "# Function to clean item names for matching:\n",
    "# Remove occurrences of \"(Rare)\" (case-insensitive), then lower-case and strip.\n",
    "def clean_item_name(name):\n",
    "    # Remove the substring (Rare) along with any extra spaces\n",
    "    name_clean = re.sub(r'\\s*\\(rare\\)', '', name, flags=re.IGNORECASE)\n",
    "    return name_clean.strip().lower()\n",
    "\n",
    "nodes_df[\"Item Name Clean\"] = nodes_df[\"Item Name\"].apply(clean_item_name)\n",
    "\n",
    "# Function to look up the item ID using the cleaned item name.\n",
    "def get_item_id(row):\n",
    "    name = row[\"Item Name Clean\"]\n",
    "    if name in item_mapping:\n",
    "        return item_mapping[name]\n",
    "    else:\n",
    "        print(f\"Error: No ID found for item '{row['Item Name']}' (cleaned as '{name}').\")\n",
    "        return None\n",
    "\n",
    "# Apply the lookup function to each row.\n",
    "nodes_df[\"ID\"] = nodes_df.apply(get_item_id, axis=1)\n",
    "\n",
    "# Reorder columns to prepend the ID.\n",
    "final_df = nodes_df[[\"ID\", \"Time\", \"Item Name\", \"Location\", \"Coordinates\"]]\n",
    "\n",
    "# Write the final merged CSV.\n",
    "final_df.to_csv(\"final_nodes_with_ids.csv\", index=False)\n",
    "print(\"Merged CSV written to 'final_nodes_with_ids.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Eorzean time (raw): 22:59\n",
      "Threshold Eorzean time (rounded): 23:00\n",
      "\n",
      "Items scheduled in the next 24 hours (24-hour military format):\n",
      "        ID   Time                    Item Name                Location  \\\n",
      "0    27833  00:00                  Broad Beans                 Il Mheg   \n",
      "71   27729  00:00                 Raw Triplite              Amh Araeng   \n",
      "1    27828  00:00                 Mist Spinach  The Rak'tika Greatwood   \n",
      "72   27731  00:00                     Raw Onyx             The Tempest   \n",
      "26   12899  00:00                      Porcini      The Churning Mists   \n",
      "..     ...    ...                          ...                     ...   \n",
      "102  12901  22:00         Abalathian Rock Salt       The Sea of Clouds   \n",
      "95   32987  22:00  Rarefied Gyr Abanian Alumen             The Fringes   \n",
      "11   33004  22:00   Rarefied Miracle Apple Log                 Il Mheg   \n",
      "10   33002  22:00         Rarefied Pixie Apple                 Il Mheg   \n",
      "22   19860  22:00                 Bamboo Shoot                  Yanxia   \n",
      "\n",
      "    Coordinates  \n",
      "0     (x24,y36)  \n",
      "71    (x20,y29)  \n",
      "1     (x34,y21)  \n",
      "72    (x16,y21)  \n",
      "26     (x24,y6)  \n",
      "..          ...  \n",
      "102     (x8,y8)  \n",
      "95    (x32,y31)  \n",
      "11     (x4,y23)  \n",
      "10     (x4,y23)  \n",
      "22    (x28,y25)  \n",
      "\n",
      "[198 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import re\n",
    "\n",
    "# -----------------------\n",
    "# 1. Compute current Eorzean time in 24-hour format\n",
    "# -----------------------\n",
    "local_epoch = int(time.time() * 1000)\n",
    "epoch = local_epoch * 20.571428571428573\n",
    "minutes = int((epoch / (1000 * 60)) % 60)\n",
    "hours_24 = int((epoch / (1000 * 60 * 60)) % 24)\n",
    "\n",
    "# Format as 24-hour time (e.g. \"13:59\")\n",
    "et_time_str = f\"{hours_24:02d}:{minutes:02d}\"\n",
    "print(\"Current Eorzean time (raw):\", et_time_str)\n",
    "\n",
    "# -----------------------\n",
    "# 2. Round up to the next hour if minutes > 0 (using 24-hour format)\n",
    "# -----------------------\n",
    "current_time = datetime.strptime(et_time_str, \"%H:%M\")\n",
    "if current_time.minute > 0:\n",
    "    threshold_time = current_time.replace(minute=0, second=0, microsecond=0) + timedelta(hours=1)\n",
    "else:\n",
    "    threshold_time = current_time\n",
    "\n",
    "print(\"Threshold Eorzean time (rounded):\", threshold_time.strftime(\"%H:%M\"))\n",
    "\n",
    "# -----------------------\n",
    "# 3. Load and process final_nodes_with_ids.csv, duplicating ambiguous AM/PM entries.\n",
    "# -----------------------\n",
    "df = pd.read_csv(\"final_nodes_with_ids.csv\")\n",
    "\n",
    "# We'll build a new list of rows (as dicts) so we can duplicate those with \"AM/PM\".\n",
    "new_rows = []\n",
    "\n",
    "def standard_parse_time(time_str):\n",
    "    \"\"\"\n",
    "    Parse a time string that does not contain the ambiguous 'AM/PM'.\n",
    "    If the string contains \"AM\" or \"PM\" (but not \"AM/PM\"), it is parsed as a 12-hour clock.\n",
    "    Otherwise, it's assumed to be already in 24-hour format.\n",
    "    \"\"\"\n",
    "    if re.search(r'\\b(AM|PM)\\b', time_str, re.IGNORECASE) and \"AM/PM\" not in time_str.upper():\n",
    "        # Ensure a space between the digits and the AM/PM part if missing.\n",
    "        time_str_fixed = re.sub(r'(\\d)(AM|PM)', r'\\1 \\2', time_str, flags=re.IGNORECASE)\n",
    "        return datetime.strptime(time_str_fixed, \"%I:%M %p\")\n",
    "    else:\n",
    "        return datetime.strptime(time_str, \"%H:%M\")\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    time_str = row[\"Time\"].strip()\n",
    "    # Check for ambiguous \"AM/PM\" marker (case-insensitive).\n",
    "    if \"AM/PM\" in time_str.upper():\n",
    "        # Remove the marker and trim spaces.\n",
    "        base_time_str = re.sub(r'\\s*AM/PM', '', time_str, flags=re.IGNORECASE).strip()\n",
    "        # Parse the base time assuming it's in 24-hour notation.\n",
    "        base_time = datetime.strptime(base_time_str, \"%H:%M\")\n",
    "        # For ambiguous times, produce two interpretations:\n",
    "        # For 12:00, use 00:00 for the AM version and keep 12:00 for the PM version.\n",
    "        if base_time.hour == 12:\n",
    "            am_time = base_time.replace(hour=0)\n",
    "            pm_time = base_time\n",
    "        else:\n",
    "            am_time = base_time\n",
    "            pm_time = base_time + timedelta(hours=12)\n",
    "        \n",
    "        # Duplicate the row for the AM version.\n",
    "        row_am = row.copy()\n",
    "        row_am[\"Parsed Time\"] = am_time\n",
    "        row_am[\"Time\"] = am_time.strftime(\"%H:%M\")\n",
    "        new_rows.append(row_am)\n",
    "        \n",
    "        # Duplicate the row for the PM version.\n",
    "        row_pm = row.copy()\n",
    "        row_pm[\"Parsed Time\"] = pm_time\n",
    "        row_pm[\"Time\"] = pm_time.strftime(\"%H:%M\")\n",
    "        new_rows.append(row_pm)\n",
    "    else:\n",
    "        # For non-ambiguous times, use the standard parser.\n",
    "        parsed = standard_parse_time(time_str)\n",
    "        row_new = row.copy()\n",
    "        row_new[\"Parsed Time\"] = parsed\n",
    "        row_new[\"Time\"] = parsed.strftime(\"%H:%M\")\n",
    "        new_rows.append(row_new)\n",
    "\n",
    "# Create a new DataFrame from the processed rows.\n",
    "df_new = pd.DataFrame(new_rows)\n",
    "\n",
    "# -----------------------\n",
    "# 4. Adjust times for wrapping past midnight and filter for the next 24 hours\n",
    "# -----------------------\n",
    "def effective_time(row_time, threshold):\n",
    "    # If the event time is earlier than the threshold, assume it's on the next day.\n",
    "    return row_time + timedelta(days=1) if row_time < threshold else row_time\n",
    "\n",
    "df_new[\"Effective Time\"] = df_new[\"Parsed Time\"].apply(lambda t: effective_time(t, threshold_time))\n",
    "\n",
    "# Define the end of the 24-hour window.\n",
    "end_time = threshold_time + timedelta(days=1)\n",
    "\n",
    "# Filter for events whose effective time is in the next 24 hours.\n",
    "df_filtered = df_new[(df_new[\"Effective Time\"] >= threshold_time) & (df_new[\"Effective Time\"] < end_time)]\n",
    "\n",
    "# Sort by the effective time.\n",
    "df_sorted = df_filtered.sort_values(by=\"Effective Time\")\n",
    "\n",
    "print(\"\\nItems scheduled in the next 24 hours (24-hour military format):\")\n",
    "print(df_sorted[[\"ID\", \"Time\", \"Item Name\", \"Location\", \"Coordinates\"]])\n",
    "df_sorted.to_csv(\"final_nodes_with_ids_sorted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data for item ID 32996. Status code: 400\n",
      "Error fetching data for item ID 32995. Status code: 400\n",
      "CSV file with market data saved as 'final_nodes_with_ids_market.csv'.\n"
     ]
    }
   ],
   "source": [
    "# requires internet connection and running universalis api\n",
    "# send a request to the universalis API for each of the next 10 items on the final_nodes_with_ids_sorted.csv\n",
    "# append to each line the value of the expected request\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# -----------------------\n",
    "# 1. Read the previously generated sorted CSV and take the first 10 rows.\n",
    "# -----------------------\n",
    "df_sorted = pd.read_csv(\"final_nodes_with_ids_sorted.csv\")\n",
    "df_top10 = df_sorted.head(10).copy()\n",
    "\n",
    "# Define new column names for the market data we want to add.\n",
    "market_columns = [\n",
    "    \"minListing_world\", \n",
    "    \"minListing_dc\", \n",
    "    \"recentPurchase_world\", \n",
    "    \"recentPurchase_dc\", \n",
    "    \"averageSalePrice_dc\", \n",
    "    \"dailySaleVelocity_dc\"\n",
    "]\n",
    "\n",
    "# Initialize the new columns with None.\n",
    "for col in market_columns:\n",
    "    df_top10[col] = None\n",
    "\n",
    "# -----------------------\n",
    "# 2. Set default world and define a function to fetch market data.\n",
    "# -----------------------\n",
    "world = \"Seraph\"\n",
    "\n",
    "def fetch_market_data(item_id, world):\n",
    "    url = f\"https://universalis.app/api/v2/aggregated/{world}/{item_id}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"results\" in data and len(data[\"results\"]) > 0:\n",
    "                result = data[\"results\"][0]\n",
    "                # Extract the required market values.\n",
    "                minListing_world = result.get(\"nq\", {}).get(\"minListing\", {}).get(\"world\", {}).get(\"price\")\n",
    "                minListing_dc = result.get(\"nq\", {}).get(\"minListing\", {}).get(\"dc\", {}).get(\"price\")\n",
    "                recentPurchase_world = result.get(\"nq\", {}).get(\"recentPurchase\", {}).get(\"world\", {}).get(\"price\")\n",
    "                recentPurchase_dc = result.get(\"nq\", {}).get(\"recentPurchase\", {}).get(\"dc\", {}).get(\"price\")\n",
    "                averageSalePrice_dc = result.get(\"nq\", {}).get(\"averageSalePrice\", {}).get(\"dc\", {}).get(\"price\")\n",
    "                dailySaleVelocity_dc = result.get(\"nq\", {}).get(\"dailySaleVelocity\", {}).get(\"dc\", {}).get(\"quantity\")\n",
    "                return {\n",
    "                    \"minListing_world\": minListing_world,\n",
    "                    \"minListing_dc\": minListing_dc,\n",
    "                    \"recentPurchase_world\": recentPurchase_world,\n",
    "                    \"recentPurchase_dc\": recentPurchase_dc,\n",
    "                    \"averageSalePrice_dc\": averageSalePrice_dc,\n",
    "                    \"dailySaleVelocity_dc\": dailySaleVelocity_dc,\n",
    "                }\n",
    "            else:\n",
    "                print(f\"No results found for item ID {item_id}\")\n",
    "        else:\n",
    "            print(f\"Error fetching data for item ID {item_id}. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception for item ID {item_id}: {e}\")\n",
    "    # Return a dict with None values if something went wrong.\n",
    "    return {col: None for col in market_columns}\n",
    "\n",
    "# -----------------------\n",
    "# 3. Loop through the first 10 rows, fetch market data for each item, and update the DataFrame.\n",
    "# -----------------------\n",
    "for idx, row in df_top10.iterrows():\n",
    "    # Assuming the column \"ID\" in the CSV corresponds to the ItemID.\n",
    "    item_id = row[\"ID\"]\n",
    "    market_data = fetch_market_data(item_id, world)\n",
    "    for key, value in market_data.items():\n",
    "        df_top10.at[idx, key] = value\n",
    "\n",
    "# -----------------------\n",
    "# 4. Save the augmented DataFrame to a new CSV file.\n",
    "# -----------------------\n",
    "df_top10.to_csv(\"final_nodes_with_ids_market.csv\", index=False)\n",
    "print(\"CSV file with market data saved as 'final_nodes_with_ids_market.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Item Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Parsed Time</th>\n",
       "      <th>Effective Time</th>\n",
       "      <th>minListing_world</th>\n",
       "      <th>minListing_dc</th>\n",
       "      <th>recentPurchase_world</th>\n",
       "      <th>recentPurchase_dc</th>\n",
       "      <th>averageSalePrice_dc</th>\n",
       "      <th>dailySaleVelocity_dc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27833</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Broad Beans</td>\n",
       "      <td>Il Mheg</td>\n",
       "      <td>(x24,y36)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27729</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Raw Triplite</td>\n",
       "      <td>Amh Araeng</td>\n",
       "      <td>(x20,y29)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.332169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27828</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Mist Spinach</td>\n",
       "      <td>The Rak'tika Greatwood</td>\n",
       "      <td>(x34,y21)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>131.314917</td>\n",
       "      <td>46.902470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27731</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Raw Onyx</td>\n",
       "      <td>The Tempest</td>\n",
       "      <td>(x16,y21)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1456.841667</td>\n",
       "      <td>93.286545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Porcini</td>\n",
       "      <td>The Churning Mists</td>\n",
       "      <td>(x24,y6)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>70.333333</td>\n",
       "      <td>10.883423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12943</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Dravanian Mistletoe</td>\n",
       "      <td>The Churning Mists</td>\n",
       "      <td>(x24,y6)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>800.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>711.962437</td>\n",
       "      <td>255.241985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32996</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Rarefied Dark Chestnut Resin</td>\n",
       "      <td>The Dravanian Forelands</td>\n",
       "      <td>(x16,y36)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32995</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Rarefied Dark Chestnut</td>\n",
       "      <td>The Dravanian Forelands</td>\n",
       "      <td>(x16,y36)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19907</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Ala Mhigan Salt Crystal</td>\n",
       "      <td>The Lochs</td>\n",
       "      <td>(x21,y29)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>355.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>391.607422</td>\n",
       "      <td>132.673739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19970</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Raw Star Spinel</td>\n",
       "      <td>The Ruby Sea</td>\n",
       "      <td>(x15,y5)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.591282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID   Time                     Item Name                 Location  \\\n",
       "0  27833  00:00                   Broad Beans                  Il Mheg   \n",
       "1  27729  00:00                  Raw Triplite               Amh Araeng   \n",
       "2  27828  00:00                  Mist Spinach   The Rak'tika Greatwood   \n",
       "3  27731  00:00                      Raw Onyx              The Tempest   \n",
       "4  12899  00:00                       Porcini       The Churning Mists   \n",
       "5  12943  00:00           Dravanian Mistletoe       The Churning Mists   \n",
       "6  32996  00:00  Rarefied Dark Chestnut Resin  The Dravanian Forelands   \n",
       "7  32995  00:00        Rarefied Dark Chestnut  The Dravanian Forelands   \n",
       "8  19907  00:00       Ala Mhigan Salt Crystal                The Lochs   \n",
       "9  19970  00:00               Raw Star Spinel             The Ruby Sea   \n",
       "\n",
       "  Coordinates          Parsed Time       Effective Time  minListing_world  \\\n",
       "0   (x24,y36)  1900-01-01 00:00:00  1900-01-02 00:00:00              11.0   \n",
       "1   (x20,y29)  1900-01-01 00:00:00  1900-01-02 00:00:00              50.0   \n",
       "2   (x34,y21)  1900-01-01 00:00:00  1900-01-02 00:00:00              46.0   \n",
       "3   (x16,y21)  1900-01-01 00:00:00  1900-01-02 00:00:00               NaN   \n",
       "4    (x24,y6)  1900-01-01 00:00:00  1900-01-02 00:00:00              73.0   \n",
       "5    (x24,y6)  1900-01-01 00:00:00  1900-01-02 00:00:00             800.0   \n",
       "6   (x16,y36)  1900-01-01 00:00:00  1900-01-02 00:00:00               NaN   \n",
       "7   (x16,y36)  1900-01-01 00:00:00  1900-01-02 00:00:00               NaN   \n",
       "8   (x21,y29)  1900-01-01 00:00:00  1900-01-02 00:00:00             355.0   \n",
       "9    (x15,y5)  1900-01-01 00:00:00  1900-01-02 00:00:00              22.0   \n",
       "\n",
       "   minListing_dc  recentPurchase_world  recentPurchase_dc  \\\n",
       "0            7.0                  19.0              150.0   \n",
       "1            5.0                  60.0                5.0   \n",
       "2            8.0                  40.0              100.0   \n",
       "3         1000.0                2000.0              500.0   \n",
       "4            5.0                  42.0               42.0   \n",
       "5          300.0                 900.0              115.0   \n",
       "6            NaN                   NaN                NaN   \n",
       "7            NaN                   NaN                NaN   \n",
       "8            4.0                 375.0              375.0   \n",
       "9            5.0                 175.0                5.0   \n",
       "\n",
       "   averageSalePrice_dc  dailySaleVelocity_dc  \n",
       "0                  NaN                   NaN  \n",
       "1             5.000000              2.332169  \n",
       "2           131.314917             46.902470  \n",
       "3          1456.841667             93.286545  \n",
       "4            70.333333             10.883423  \n",
       "5           711.962437            255.241985  \n",
       "6                  NaN                   NaN  \n",
       "7                  NaN                   NaN  \n",
       "8           391.607422            132.673739  \n",
       "9             5.000000              2.591282  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the final CSV with market data (20 rows)\n",
    "df_market = pd.read_csv(\"final_nodes_with_ids_market.csv\")\n",
    "\n",
    "from IPython.display import display\n",
    "display(df_market)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file with market data saved as 'final_nodes_with_ids_market.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# -----------------------\n",
    "# 1. Read the previously generated sorted CSV and take the first 10 rows that do NOT contain \"Rarefied\" in the Item Name.\n",
    "# -----------------------\n",
    "df_sorted = pd.read_csv(\"final_nodes_with_ids_sorted.csv\")\n",
    "\n",
    "# Filter out rows that have \"Rarefied\" in the Item Name (case-insensitive)\n",
    "df_filtered = df_sorted[~df_sorted[\"Item Name\"].str.contains(\"Rarefied\", case=False, na=False)]\n",
    "df_top10 = df_filtered.head(10).copy()\n",
    "\n",
    "# Define new column names for the market data we want to add.\n",
    "market_columns = [\n",
    "    \"minListing_world\", \n",
    "    \"minListing_dc\", \n",
    "    \"recentPurchase_world\", \n",
    "    \"recentPurchase_dc\", \n",
    "    \"averageSalePrice_dc\", \n",
    "    \"dailySaleVelocity_dc\"\n",
    "]\n",
    "\n",
    "# Initialize the new columns with None.\n",
    "for col in market_columns:\n",
    "    df_top10[col] = None\n",
    "\n",
    "# -----------------------\n",
    "# 2. Set default world and define a function to fetch market data.\n",
    "# -----------------------\n",
    "world = \"Seraph\"\n",
    "\n",
    "def fetch_market_data(item_id, world):\n",
    "    url = f\"https://universalis.app/api/v2/aggregated/{world}/{item_id}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"results\" in data and len(data[\"results\"]) > 0:\n",
    "                result = data[\"results\"][0]\n",
    "                # Extract the required market values.\n",
    "                minListing_world = result.get(\"nq\", {}).get(\"minListing\", {}).get(\"world\", {}).get(\"price\")\n",
    "                minListing_dc = result.get(\"nq\", {}).get(\"minListing\", {}).get(\"dc\", {}).get(\"price\")\n",
    "                recentPurchase_world = result.get(\"nq\", {}).get(\"recentPurchase\", {}).get(\"world\", {}).get(\"price\")\n",
    "                recentPurchase_dc = result.get(\"nq\", {}).get(\"recentPurchase\", {}).get(\"dc\", {}).get(\"price\")\n",
    "                averageSalePrice_dc = result.get(\"nq\", {}).get(\"averageSalePrice\", {}).get(\"dc\", {}).get(\"price\")\n",
    "                dailySaleVelocity_dc = result.get(\"nq\", {}).get(\"dailySaleVelocity\", {}).get(\"dc\", {}).get(\"quantity\")\n",
    "                return {\n",
    "                    \"minListing_world\": minListing_world,\n",
    "                    \"minListing_dc\": minListing_dc,\n",
    "                    \"recentPurchase_world\": recentPurchase_world,\n",
    "                    \"recentPurchase_dc\": recentPurchase_dc,\n",
    "                    \"averageSalePrice_dc\": averageSalePrice_dc,\n",
    "                    \"dailySaleVelocity_dc\": dailySaleVelocity_dc,\n",
    "                }\n",
    "            else:\n",
    "                print(f\"No results found for item ID {item_id}\")\n",
    "        else:\n",
    "            print(f\"Error fetching data for item ID {item_id}. Status code: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception for item ID {item_id}: {e}\")\n",
    "    # Return a dict with None values if something went wrong.\n",
    "    return {col: None for col in market_columns}\n",
    "\n",
    "# -----------------------\n",
    "# 3. Loop through the first 10 rows, fetch market data for each item, and update the DataFrame.\n",
    "# -----------------------\n",
    "for idx, row in df_top10.iterrows():\n",
    "    # Assuming the column \"ID\" in the CSV corresponds to the ItemID.\n",
    "    item_id = row[\"ID\"]\n",
    "    market_data = fetch_market_data(item_id, world)\n",
    "    for key, value in market_data.items():\n",
    "        df_top10.at[idx, key] = value\n",
    "\n",
    "# -----------------------\n",
    "# 4. Save the augmented DataFrame to a new CSV file.\n",
    "# -----------------------\n",
    "df_top10.to_csv(\"final_nodes_with_ids_market.csv\", index=False)\n",
    "print(\"CSV file with market data saved as 'final_nodes_with_ids_market.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Item Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Parsed Time</th>\n",
       "      <th>Effective Time</th>\n",
       "      <th>minListing_world</th>\n",
       "      <th>minListing_dc</th>\n",
       "      <th>recentPurchase_world</th>\n",
       "      <th>recentPurchase_dc</th>\n",
       "      <th>averageSalePrice_dc</th>\n",
       "      <th>dailySaleVelocity_dc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27833</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Broad Beans</td>\n",
       "      <td>Il Mheg</td>\n",
       "      <td>(x24,y36)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27729</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Raw Triplite</td>\n",
       "      <td>Amh Araeng</td>\n",
       "      <td>(x20,y29)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.332151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27828</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Mist Spinach</td>\n",
       "      <td>The Rak'tika Greatwood</td>\n",
       "      <td>(x34,y21)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>131.314917</td>\n",
       "      <td>46.902108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27731</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Raw Onyx</td>\n",
       "      <td>The Tempest</td>\n",
       "      <td>(x16,y21)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>500</td>\n",
       "      <td>1456.841667</td>\n",
       "      <td>93.285901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Porcini</td>\n",
       "      <td>The Churning Mists</td>\n",
       "      <td>(x24,y6)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>70.333333</td>\n",
       "      <td>10.883347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12943</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Dravanian Mistletoe</td>\n",
       "      <td>The Churning Mists</td>\n",
       "      <td>(x24,y6)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>800.0</td>\n",
       "      <td>300</td>\n",
       "      <td>900</td>\n",
       "      <td>115</td>\n",
       "      <td>711.962437</td>\n",
       "      <td>255.240221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19907</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Ala Mhigan Salt Crystal</td>\n",
       "      <td>The Lochs</td>\n",
       "      <td>(x21,y29)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>355.0</td>\n",
       "      <td>4</td>\n",
       "      <td>375</td>\n",
       "      <td>375</td>\n",
       "      <td>391.607422</td>\n",
       "      <td>132.673008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19970</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Raw Star Spinel</td>\n",
       "      <td>The Ruby Sea</td>\n",
       "      <td>(x15,y5)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.591268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12538</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Adamantite Ore</td>\n",
       "      <td>Azys Lla</td>\n",
       "      <td>(x24,y6)</td>\n",
       "      <td>1900-01-01 00:00:00</td>\n",
       "      <td>1900-01-02 00:00:00</td>\n",
       "      <td>515.0</td>\n",
       "      <td>95</td>\n",
       "      <td>519</td>\n",
       "      <td>880</td>\n",
       "      <td>643.249723</td>\n",
       "      <td>467.982670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5121</td>\n",
       "      <td>01:00</td>\n",
       "      <td>Darksteel Ore</td>\n",
       "      <td>Coerthas Central Highlands</td>\n",
       "      <td>(x27,y19)</td>\n",
       "      <td>1900-01-01 01:00:00</td>\n",
       "      <td>1900-01-02 01:00:00</td>\n",
       "      <td>777.0</td>\n",
       "      <td>530</td>\n",
       "      <td>667</td>\n",
       "      <td>800</td>\n",
       "      <td>682.480417</td>\n",
       "      <td>10248.191723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID   Time                Item Name                    Location  \\\n",
       "0  27833  00:00              Broad Beans                     Il Mheg   \n",
       "1  27729  00:00             Raw Triplite                  Amh Araeng   \n",
       "2  27828  00:00             Mist Spinach      The Rak'tika Greatwood   \n",
       "3  27731  00:00                 Raw Onyx                 The Tempest   \n",
       "4  12899  00:00                  Porcini          The Churning Mists   \n",
       "5  12943  00:00      Dravanian Mistletoe          The Churning Mists   \n",
       "6  19907  00:00  Ala Mhigan Salt Crystal                   The Lochs   \n",
       "7  19970  00:00          Raw Star Spinel                The Ruby Sea   \n",
       "8  12538  00:00           Adamantite Ore                    Azys Lla   \n",
       "9   5121  01:00            Darksteel Ore  Coerthas Central Highlands   \n",
       "\n",
       "  Coordinates          Parsed Time       Effective Time  minListing_world  \\\n",
       "0   (x24,y36)  1900-01-01 00:00:00  1900-01-02 00:00:00              11.0   \n",
       "1   (x20,y29)  1900-01-01 00:00:00  1900-01-02 00:00:00              50.0   \n",
       "2   (x34,y21)  1900-01-01 00:00:00  1900-01-02 00:00:00              46.0   \n",
       "3   (x16,y21)  1900-01-01 00:00:00  1900-01-02 00:00:00               NaN   \n",
       "4    (x24,y6)  1900-01-01 00:00:00  1900-01-02 00:00:00              73.0   \n",
       "5    (x24,y6)  1900-01-01 00:00:00  1900-01-02 00:00:00             800.0   \n",
       "6   (x21,y29)  1900-01-01 00:00:00  1900-01-02 00:00:00             355.0   \n",
       "7    (x15,y5)  1900-01-01 00:00:00  1900-01-02 00:00:00              22.0   \n",
       "8    (x24,y6)  1900-01-01 00:00:00  1900-01-02 00:00:00             515.0   \n",
       "9   (x27,y19)  1900-01-01 01:00:00  1900-01-02 01:00:00             777.0   \n",
       "\n",
       "   minListing_dc  recentPurchase_world  recentPurchase_dc  \\\n",
       "0              7                    19                150   \n",
       "1              5                    60                  5   \n",
       "2              8                    40                100   \n",
       "3           1000                  2000                500   \n",
       "4              5                    42                 42   \n",
       "5            300                   900                115   \n",
       "6              4                   375                375   \n",
       "7              5                   175                  5   \n",
       "8             95                   519                880   \n",
       "9            530                   667                800   \n",
       "\n",
       "   averageSalePrice_dc  dailySaleVelocity_dc  \n",
       "0                  NaN                   NaN  \n",
       "1             5.000000              2.332151  \n",
       "2           131.314917             46.902108  \n",
       "3          1456.841667             93.285901  \n",
       "4            70.333333             10.883347  \n",
       "5           711.962437            255.240221  \n",
       "6           391.607422            132.673008  \n",
       "7             5.000000              2.591268  \n",
       "8           643.249723            467.982670  \n",
       "9           682.480417          10248.191723  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Read the final CSV with market data.\n",
    "df_market = pd.read_csv(\"final_nodes_with_ids_market.csv\")\n",
    "\n",
    "# Ensure we only display rows that do NOT have \"Rarefied\" in the Item Name.\n",
    "df_market_filtered = df_market[~df_market[\"Item Name\"].str.contains(\"Rarefied\", case=False, na=False)]\n",
    "\n",
    "# Display the filtered DataFrame.\n",
    "display(df_market_filtered)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
